{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from sqlalchemy.orm import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n"
     ]
    }
   ],
   "source": [
    "DATABASE_URL = \"postgresql://postgres@localhost:5432/my-rag-example\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def read_notebook(file_path):\n",
    "    \"\"\"Read and parse the Jupyter Notebook.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "    return notebook\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def extract_chunks(notebook, chunk_size=500):\n",
    "    \"\"\"Extract and chunk the contents of the notebook.\"\"\"\n",
    "    chunks = []\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown' or cell.cell_type == 'code':\n",
    "            content = cell.source\n",
    "            # Split content into smaller chunks\n",
    "            for i in range(0, len(content), chunk_size):\n",
    "                chunks.append(content[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "def generate_chunks(input_text):\n",
    "    return [sentence.strip() for sentence in input_text.strip().split('.') if sentence.strip()]\n",
    "\n",
    "def generate_embeddings_with_chunks(chunks, embedding_model=\"text-embedding-ada-002\"):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embedding = get_embedding(chunk, model=embedding_model)\n",
    "        embeddings.append(embedding)\n",
    "    return [{\"content\": chunk, \"embedding\": embedding} for chunk, embedding in zip(chunks, embeddings)]\n",
    "\n",
    "def create_resource(content):\n",
    "    try:\n",
    "        engine = create_engine(DATABASE_URL)\n",
    "        with Session(engine) as session:\n",
    "            try:\n",
    "                resource_id = str(uuid.uuid4())\n",
    "                \n",
    "                session.execute(\n",
    "                    text(\"INSERT INTO resources (id, content, created_at, updated_at) VALUES (:id, :content, now(), now())\"),\n",
    "                    {\"id\": resource_id, \"content\": content}\n",
    "                )\n",
    "\n",
    "                chunks = generate_chunks(content)\n",
    "                embeddings = generate_embeddings_with_chunks(chunks)\n",
    "\n",
    "                for embedding in embeddings:\n",
    "                    session.execute(\n",
    "                        text(\"INSERT INTO embeddings (id, resource_id, content, embedding) VALUES (:id, :resource_id, :content, :embedding)\"),\n",
    "                        {\n",
    "                            \"id\": str(uuid.uuid4()),\n",
    "                            \"resource_id\": resource_id,\n",
    "                            \"content\": embedding[\"content\"],\n",
    "                            \"embedding\": embedding[\"embedding\"]\n",
    "                        }\n",
    "                    )\n",
    "                \n",
    "                session.commit()\n",
    "                return \"Resource successfully created.\"\n",
    "            \n",
    "            except Exception as inner_e:\n",
    "                session.rollback()\n",
    "                return f\"Insertion Error: {str(inner_e)}\"\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        return f\"SQLAlchemyError: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Unexpected Error: {str(e)}\"\n",
    "\n",
    "            \n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"sample.ipynb\"\n",
    "    \n",
    "    # Step 1: Read the notebook\n",
    "    notebook = read_notebook(file_path)\n",
    "    \n",
    "    # Step 2: Extract Markdown content (ignore code cells)\n",
    "    markdown_content = \"\\n\".join(\n",
    "        cell.source for cell in notebook.cells if cell.cell_type == 'markdown'\n",
    "    )\n",
    "\n",
    "    # Step 5: Save resource and embeddings to PostgreSQL\n",
    "    result = create_resource(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numerical-methods-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
